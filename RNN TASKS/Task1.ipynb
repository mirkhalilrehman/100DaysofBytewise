{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyjGKMN51rZk"
      },
      "source": [
        "1. Implementing a Basic RNN Model\n",
        "○ Task: Using a dataset of your choice (e.g., text, time-series data), implement a\n",
        "basic RNN model. Train the model to perform a sequence task such as text\n",
        "generation, sentiment analysis, or time-series prediction.\n",
        "○ Deliverable: Perform this experimentation in a notebook and provide a detailed\n",
        "explanation or comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpd5B-5V1rZm",
        "outputId": "63c950e3-83d5-4a2b-fbd1-de02de0a7ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 91ms/step - accuracy: 0.6100 - loss: 0.6340 - val_accuracy: 0.7952 - val_loss: 0.4484\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 69ms/step - accuracy: 0.8387 - loss: 0.3726 - val_accuracy: 0.8258 - val_loss: 0.4038\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9101 - loss: 0.2278 - val_accuracy: 0.6455 - val_loss: 0.7101\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 71ms/step - accuracy: 0.9435 - loss: 0.1600 - val_accuracy: 0.7944 - val_loss: 0.6051\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 69ms/step - accuracy: 0.9912 - loss: 0.0340 - val_accuracy: 0.7804 - val_loss: 0.7432\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.7782 - loss: 0.7572\n",
            "Test Accuracy: 0.780\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "# Load dataset (IMDB - already tokenized)\n",
        "max_features = 10000  # Only consider the top 10,000 words\n",
        "maxlen = 500          # Maximum review length to consider\n",
        "\n",
        "# Load IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
        "model.add(SimpleRNN(units=64, return_sequences=False))  # Basic RNN layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP8cXXmq1rZo"
      },
      "source": [
        "2. Stacking RNN Layers and Bi-directional RNNs\n",
        "○ Task: Modify your basic RNN model by stacking multiple RNN layers and also\n",
        "converting it into a bi-directional RNN. Analyze the performance improvement (if\n",
        "any) compared to the basic RNN model. (Note: Separate Implementation of\n",
        "Stacked RNN &amp; Bi-Directional RNN)\n",
        "○ Deliverable: Perform this experimentation in a notebook and provide a detailed\n",
        "explanation or comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK3IKhG61rZp",
        "outputId": "e4c49a31-77c9-4c07-93f4-98f0b2b1459f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 136ms/step - accuracy: 0.5836 - loss: 0.6492 - val_accuracy: 0.7526 - val_loss: 0.5079\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 133ms/step - accuracy: 0.8468 - loss: 0.3655 - val_accuracy: 0.8462 - val_loss: 0.3647\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 135ms/step - accuracy: 0.9122 - loss: 0.2278 - val_accuracy: 0.8253 - val_loss: 0.4022\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 133ms/step - accuracy: 0.9406 - loss: 0.1615 - val_accuracy: 0.7966 - val_loss: 0.5349\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 132ms/step - accuracy: 0.9699 - loss: 0.0855 - val_accuracy: 0.8120 - val_loss: 0.5659\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.8124 - loss: 0.5634\n",
            "Stacked RNN Test Accuracy: 0.812\n"
          ]
        }
      ],
      "source": [
        "# Stacked RNN Model\n",
        "stacked_model = Sequential()\n",
        "stacked_model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
        "stacked_model.add(SimpleRNN(units=64, return_sequences=True))  # Return sequences to stack another RNN\n",
        "stacked_model.add(SimpleRNN(units=64))  # Second RNN layer\n",
        "stacked_model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "stacked_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the stacked RNN model\n",
        "history_stacked = stacked_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the stacked model\n",
        "test_loss_stacked, test_acc_stacked = stacked_model.evaluate(x_test, y_test)\n",
        "print(f'Stacked RNN Test Accuracy: {test_acc_stacked:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH6ZQ2-Q1rZp",
        "outputId": "56bf04a5-88a7-488e-8ea5-958cb52208aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 134ms/step - accuracy: 0.6142 - loss: 0.6240 - val_accuracy: 0.8252 - val_loss: 0.4075\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 132ms/step - accuracy: 0.8493 - loss: 0.3543 - val_accuracy: 0.6806 - val_loss: 0.5790\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 131ms/step - accuracy: 0.8175 - loss: 0.4034 - val_accuracy: 0.8209 - val_loss: 0.4182\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 132ms/step - accuracy: 0.9077 - loss: 0.2399 - val_accuracy: 0.8338 - val_loss: 0.4360\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 130ms/step - accuracy: 0.9512 - loss: 0.1352 - val_accuracy: 0.8062 - val_loss: 0.5461\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.8045 - loss: 0.5515\n",
            "Bi-directional RNN Test Accuracy: 0.806\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# Bi-directional RNN Model\n",
        "bi_rnn_model = Sequential()\n",
        "bi_rnn_model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
        "bi_rnn_model.add(Bidirectional(SimpleRNN(units=64)))  # Bi-directional RNN\n",
        "bi_rnn_model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "bi_rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the bi-directional RNN model\n",
        "history_bi_rnn = bi_rnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the bi-directional model\n",
        "test_loss_bi_rnn, test_acc_bi_rnn = bi_rnn_model.evaluate(x_test, y_test)\n",
        "print(f'Bi-directional RNN Test Accuracy: {test_acc_bi_rnn:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Exploring Hybrid Architectures\n",
        "○ Task: Implement a hybrid architecture by combining your RNN model with\n",
        "another model (e.g., CNN, Attention mechanism). Train this hybrid model on the\n",
        "same dataset and compare its performance with the previous models.\n",
        "\n",
        "○ Deliverable: Submit the Python code in a notebook for the hybrid model along\n",
        "with a report discussing the results, challenges faced, and the benefits (or\n",
        "drawbacks) of using a hybrid approach."
      ],
      "metadata": {
        "id": "tIF9zFyk4kix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "# Hybrid CNN-RNN Model\n",
        "hybrid_model = Sequential()\n",
        "hybrid_model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
        "\n",
        "# Add 1D Convolutional layer\n",
        "hybrid_model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "hybrid_model.add(MaxPooling1D(pool_size=4))\n",
        "\n",
        "# Add RNN layer\n",
        "hybrid_model.add(SimpleRNN(units=64))\n",
        "\n",
        "# Dense output layer\n",
        "hybrid_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history_hybrid = hybrid_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the hybrid model\n",
        "test_loss_hybrid, test_acc_hybrid = hybrid_model.evaluate(x_test, y_test)\n",
        "print(f'Hybrid CNN-RNN Test Accuracy: {test_acc_hybrid:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CizUrKvy4fSN",
        "outputId": "20ccdec2-ecda-44f0-ea36-6a67b4b02736"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.6093 - loss: 0.6111 - val_accuracy: 0.8765 - val_loss: 0.2972\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9064 - loss: 0.2361 - val_accuracy: 0.8842 - val_loss: 0.2873\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9504 - loss: 0.1437 - val_accuracy: 0.8701 - val_loss: 0.3359\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9771 - loss: 0.0698 - val_accuracy: 0.8711 - val_loss: 0.3758\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9943 - loss: 0.0216 - val_accuracy: 0.8719 - val_loss: 0.4686\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8701 - loss: 0.4631\n",
            "Hybrid CNN-RNN Test Accuracy: 0.872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWC6k_OZ6HWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}